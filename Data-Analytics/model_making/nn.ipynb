{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41907/62274928.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  inputs = pd.read_csv('inputs.csv')\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.read_csv('inputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.drop(columns=['Unnamed: 0.1','Unnamed: 0'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DCA License Number', 'License Type', 'License Expiration Date',\n",
       "       'License Creation Date', 'Industry', 'Business Name',\n",
       "       'Address Building', 'Address ZIP', 'Address Borough', 'BIN', 'Latitude',\n",
       "       'Longitude', 'zipcode', 'city', 'state', 'lat', 'lng', 'population',\n",
       "       'density', 'land_area', 'water_area', 'zip', 'hour 0', 'hour 1',\n",
       "       'hour 2', 'hour 3', 'hour 4', 'hour 5', 'hour 6', 'hour 7', 'hour 8',\n",
       "       'hour 9', 'hour 10', 'hour 11', 'hour 12', 'hour 13', 'hour 14',\n",
       "       'hour 15', 'hour 16', 'hour 17', 'hour 18', 'hour 19', 'hour 20',\n",
       "       'hour 21', 'hour 22', 'hour 23', 'total counts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         11214.0\n",
       "1         10028.0\n",
       "2         10023.0\n",
       "3         10460.0\n",
       "4         10454.0\n",
       "           ...   \n",
       "182061    11235.0\n",
       "182062    11231.0\n",
       "182063    10001.0\n",
       "182064    10301.0\n",
       "182065    11231.0\n",
       "Name: zipcode, Length: 182066, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = pd.DataFrame(inputs['zipcode'])\n",
    "x_set = inputs[['Industry','lng', 'lat', 'hour 0', 'hour 1', 'hour 2', 'hour 3', 'hour 4', 'hour 5', 'hour 6', 'hour 7', 'hour 8', 'hour 9', 'hour 10', 'hour 11', 'hour 12', 'hour 12', 'hour 13', 'hour 14', 'hour 15', 'hour 16', 'hour 17', 'hour 18', 'hour 19', 'hour 20', 'hour 21', 'hour 22', 'hour 23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182066, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_set: (182066, 88)\n",
      "Shape of y_set_encoded: (182066, 116)\n",
      "Memory usage of x_set (MB): 122.23682022094727\n",
      "Memory usage of y_set_encoded (MB): 161.13031387329102\n",
      "Data types in x_set:\n",
      " lng                                float64\n",
      "lat                                float64\n",
      "hour 0                             float64\n",
      "hour 1                             float64\n",
      "hour 2                             float64\n",
      "                                    ...   \n",
      "Industry_Ticket Seller Business    float64\n",
      "Industry_Tobacco Retail Dealer     float64\n",
      "Industry_Tow Truck Company         float64\n",
      "Industry_Tow Truck Driver          float64\n",
      "Industry_Tow Truck Exemption       float64\n",
      "Length: 88, dtype: object\n",
      "Data types in y_set_encoded:\n",
      " 0      float64\n",
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "        ...   \n",
      "111    float64\n",
      "112    float64\n",
      "113    float64\n",
      "114    float64\n",
      "115    float64\n",
      "Length: 116, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Encoding the 'Industry' column in x_set\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "industry_encoded = encoder.fit_transform(x_set[['Industry']])\n",
    "industry_encoded_df = pd.DataFrame(industry_encoded, columns=encoder.get_feature_names_out(['Industry']))\n",
    "\n",
    "# Combine encoded industry with the rest of x_set\n",
    "x_set = pd.concat([x_set.reset_index(drop=True), industry_encoded_df], axis=1).drop(columns=['Industry'])\n",
    "\n",
    "# Encode y_set if needed (example for binary classification)\n",
    "y_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_set_encoded = y_encoder.fit_transform(y_set)\n",
    "y_set_encoded = pd.DataFrame(y_set_encoded)\n",
    "\n",
    "# Check shapes and memory usage\n",
    "print(\"Shape of x_set:\", x_set.shape)\n",
    "print(\"Shape of y_set_encoded:\", y_set_encoded.shape)\n",
    "print(\"Memory usage of x_set (MB):\", x_set.memory_usage(deep=True).sum() / 1024**2)\n",
    "print(\"Memory usage of y_set_encoded (MB):\", y_set_encoded.memory_usage(deep=True).sum() / 1024**2)\n",
    "print(\"Data types in x_set:\\n\", x_set.dtypes)\n",
    "print(\"Data types in y_set_encoded:\\n\", y_set_encoded.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_set_tensor: torch.Size([182066, 88])\n",
      "Shape of y_set_tensor: torch.Size([182066, 116])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "x_set_tensor = torch.tensor(x_set.values, dtype=torch.float32)\n",
    "y_set_tensor = torch.tensor(y_set_encoded.values, dtype=torch.float32)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(x_set_tensor, y_set_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"Shape of x_set_tensor:\", x_set_tensor.shape)\n",
    "print(\"Shape of y_set_tensor:\", y_set_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_set_tensor, y_set_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoaders for training and testing sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (input_layer): Linear(in_features=88, out_features=5, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=5, out_features=5, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=5, out_features=116, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=88, hidden_size=5, num_layers=5, output_size=116):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define the input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass through input layer\n",
    "        x = self.relu(self.input_layer(x))\n",
    "        \n",
    "        # Pass through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.relu(layer(x))\n",
    "        \n",
    "        # Pass through output layer\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = SimpleNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN().to(device)\n",
    "\n",
    "# Check where the model is located\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 14566/14566 [00:30<00:00, 478.20it/s, loss=4.64]\n",
      "Epoch 2/20:  72%|███████▏  | 10456/14566 [56:41<22:16,  3.07it/s, loss=3.33] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 15\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Update progress bar description\u001b[39;00m\n\u001b[1;32m     18\u001b[0m train_progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mtrain_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Create a progress bar for the training loop\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for inputs, targets in train_progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar description\n",
    "        train_progress_bar.set_postfix(loss=train_loss/len(train_dataloader))\n",
    "    \n",
    "    # Evaluation loop with progress bar\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.6404\n",
      "Test Accuracy: 0.0201\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "test_loss = 0\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, actual = torch.max(targets, 1)\n",
    "        correct_predictions += (predicted == actual).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "test_loss /= len(test_dataloader)  # Calculate the average loss\n",
    "accuracy = correct_predictions / total_predictions  # Calculate accuracy\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
